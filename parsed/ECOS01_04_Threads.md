\\--- PÁGINA 1 \\---  # **Sistemas Operacionais**  ## **Threads**  Prof. Otávio Gomes   otavio.gomes@unifei.edu.br   \\--- PÁGINA 2 \\---  ## **O modelo de Processo**  * Possui um espaço de endereço exclusivo (0 até algum endereço máximo);   * Possui uma única linha de execução (thread);   * Agrupamento de recursos (espaço de endereço com texto e dados do programa, arquivos abertos, processos filhos, tratadores de sinais, alarmes pendentes, etc.)  \\--- PÁGINA 3 \\---  ## **O modelo de Thread**  * Conjunto de threads compõe as linhas de execuções de um processo;   * Um espaço de endereço e múltiplas linhas de controle;   * Threads compartilham um mesmo espaço de endereço (sendo menos independentes que os processos), mas possuem recursos particulares (PC, registradores, pilha).  \\--- PÁGINA 4 \\---  ## **Threads: Single-thread e Multithread**  \\[Imagem: Processo single-thread vs. multithread\\]   \\*A imagem compara dois modelos:  * **single-threaded process:** Um único processo com um espaço de endereço (code, data, files) e uma única linha de execução (thread), com seus próprios registers e stack.   * **multithreaded process:** Um único processo com um espaço de endereço compartilhado (code, data, files), mas com múltiplas threads. Cada thread tem seu próprio conjunto de registers e sua própria stack.\\*  \\--- PÁGINA 5 \\---  ## **Threads: Vantagens**  * Em muitas aplicações há múltiplas atividades ao mesmo tempo;   * CPU-bound e I/O-bound podem se sobrepor, acelerando a aplicação.  \\[Imagem: Exemplo de uso de threads em um editor de texto\\]   Um diagrama ilustra três threads em um editor de texto. Uma thread interage com o usuário via teclado. Outra thread formata o texto em segundo plano. Uma terceira thread realiza backups periódicos em disco. Todas operam concorrentemente, melhorando a responsividade.   \\--- PÁGINA 6 \\---  ## **Threads: Vantagens**  \\[Imagem: Diagrama de Fluxo de Processos, Threads e Tasks\\]   Um fluxograma mostrando um Program (ex: Ms Word) que pode ter várias instâncias (processos). O Process 1 (Criando Novo Doc) tem três Threads (UI thread, Worker para salvar, Worker para fontes). O Process 3 (Abrindo doc) usa Tasks, que rodam em um threadpool, sendo mais simples e eficientes para operações curtas, evitando o custo de criar threads do SO.   \\--- PÁGINA 7 \\---  ## **Threads: Vantagens**  * Podemos decompô-las em atividades paralelas;   * Algumas tarefas precisam de compartilhamento do espaço de endereçamento.  \\[Imagem: Threads executando em múltiplas CPUs\\]   O diagrama mostra dois processos, cada um com várias threads. Algumas threads estão executando (-\\> CPU), enquanto outras estão bloqueadas (-\\> blocked). Isso ilustra como threads de diferentes processos podem ser escalonadas para múltiplas CPUs.   \\--- PÁGINA 8 \\---  ## **Threads: Vantagens**  * **Tempo de resposta:** programa dividido em várias linhas de execução.     * Ex. Writer: user interface, keystrokes, spellchecker, file I/O   * **Compartilhamento de recursos:** threads compartilham código e dados do processo pai.     * processos precisam de mecanismos de IPC (memória compartilhada, mensagens)   * **Economia:** É mais barato criar threads no processo do que criar novos processos filhos.     * Ex. Solaris: criação 30x mais rápida, troca de contexto 5x mais rápida   * **Escalabilidade:** threads podem rodar em paralelo em diferentes núcleos de CPU.     * um processo de uma thread só pode rodar em um núcleo só  \\--- PÁGINA 9 \\---  ## **Threads: Vantagens**  * Úteis em sistemas com múltiplas CPUs \\>\\> Paralelismo real.   * Arquitetura de servidores multithread:  \\[Imagem: Arquitetura de servidor multithread\\]   Um diagrama de fluxo: (1) um client envia um request para o server. (2) O servidor cria uma nova thread para atender à requisição. (3) O servidor, enquanto a nova thread trabalha, continua ouvindo por novas requisições de outros clientes.   \\--- PÁGINA 10 \\---  ## **Threads: Paralelismo**  * **Paralelismo de dados** tem como foco a distribuição de partes (subsets) do mesmo dado em múltiplos núcleos de processamento (cores) e a realização da mesma operação em cada um dos núcleos.   * **Paralelismo de tarefa** envolve a distribuição não dos dados, mas das tarefas em múltiplos núcleos de processamento (cores). Cada thread executa uma operação específica.  \\--- PÁGINA 11 \\---  ## **Threads: Troca de contexto**  * **Preemptiva:**     * Controle do sistema operacional;     * Compartilhamento da CPU é garantido.   * **Cooperativa:**     * Controle da thread;     * Compartilhamento da CPU não é garantido.  \\--- PÁGINA 12 \\---  ## **Threads: Desvantagens**  Problemas (issues) incluem:  * Cancelamento de thread;   * Controle/manuseio de sinais (signal handling);   * Manuseio (handling) de dados em uma thread específica;   * Escalonamento (scheduler) de ações.  **Cancelamento:**  * **Cancelamento assíncrono** finaliza a thread-alvo imediatamente;   * **Cancelamento aprovado (deferred cancellation)** permite que a thread-alvo verifique periodicamente se deve ser cancelada.  \\--- PÁGINA 13 \\---  ## **Threads: Desvantagens**  * Como cada thread pode ter acesso a qualquer endereço de memória dentro do espaço de endereçamento do processo:     * Uma thread pode ler, escrever ou apagar a pilha ou as variáveis globais de outra thread. Exemplo:       a \\= b \\+ c;       x \\= a \\+ y;  * Necessidade de sincronizar a execução (será visto nas próximas aulas).  \\--- PÁGINA 14 \\---  ## **Threads: Recursos compartilhados**  * Acesso concorrente a dados compartilhados pode resultar em inconsistências;   * **Condições de corrida (race conditions):**     * Situação onde dois ou mais processos (ou threads) acessam e manipulam recursos compartilhados simultaneamente.  \\--- PÁGINA 15 \\---  ## **Threads: Recursos compartilhados**  \\[Imagem: Exemplo de condição de corrida em um spooler\\]   A imagem mostra um diretório de spooler. O Process A lê o próximo slot livre (in=7) para colocar um arquivo. Antes de colocar o arquivo, ele é interrompido. O Process B também lê in=7, coloca seu arquivo lá e incrementa in. Quando o Process A volta, ele também coloca seu arquivo no slot 7, sobrescrevendo o arquivo do processo B.   \\--- PÁGINA 16 \\---  ## **Threads: Recursos compartilhados**  * **Seção crítica:** N processos competem para usar alguma estrutura de dados compartilhada (será visto nas próximas aulas).  \\[Imagem: Seção Crítica\\]   Dois diagramas mostrando o conceito de seção crítica. O primeiro, incorreto, mostra vários processos (P1, P2, P3, P4) dentro da seção crítica ao mesmo tempo. O segundo, correto, mostra apenas um processo (P1) dentro da seção crítica, enquanto os outros esperam do lado de fora.   \\--- PÁGINA 17 \\---  ## **Threads: Java Threads State Diagram**  \\[Imagem: Diagrama de estados de Threads Java\\]   \\*Um diagrama de estados para threads em Java:  * New: Após new MyThread().   * Runnable: Após myThread.start().   * Running: Quando o Scheduler escolhe a thread.   * Waiting: Entra por cond.wait(), sai por cond.notify().   * Timed Waiting: Entra por sleep() ou wait(timeout).   * Blocked: Tenta acessar um recurso guardado.   * Terminated: Quando o método run() retorna.\\*  \\--- PÁGINA 18 \\---  ## **Threads: Windows Threads State Diagram**  \\[Imagem: Diagrama de estados de Threads no Windows\\]   Um diagrama de estados mais complexo para threads do Windows, dividido em Runnable e Not runnable. Os estados incluem Ready, Standby, Running, Waiting, Transition, e Terminated.   \\--- PÁGINA 19 \\---  ## **Threads: Execução concorrente \\- Mononúcleo**  \\[Imagem: Execução concorrente em um núcleo\\]   Uma linha do tempo mostrando um único núcleo (single core) executando pedaços das threads T1, T2, T3 e T4 de forma intercalada. Isso cria a ilusão de paralelismo.   \\--- PÁGINA 20 \\---  ## **Threads: Execução paralela \\- Multinúcleo**  \\[Imagem: Execução paralela em dois núcleos\\]   Duas linhas do tempo, uma para core 1 e outra para core 2\\. O core 1 executa as threads T1 e T3, enquanto o core 2 executa T2 e T4 simultaneamente. Isso é paralelismo real.   \\--- PÁGINA 21 \\---  ## **Threads: Execução paralela \\- Multinúcleo**  \\[Imagem: Escalonamento de threads em multinúcleo\\]   Um diagrama mostrando um Scheduler que considera threads de múltiplos processos (A, B, C, D, E) e as seleciona para serem executadas em múltiplos CPUs.   \\--- PÁGINA 22 \\---  ## **Threads: Programação para Multinúcleo**  Sistemas multicore apresentam novos desafios para os programadores:  * **Identificar tarefas:** seções do programa que podem ser divididas entre threads.   * **Balanceamento:** equalizar o trabalho a ser realizado por cada thread.   * **Divisão dos dados:** para que possam ser acessados/manipulados em multicore.   * **Dependência de dados:** entre duas ou mais threads, cujo acesso deve ser sincronizado.   * **Teste e depuração:** muitos caminhos diferentes de execução são possíveis.  \\--- PÁGINA 23 \\---  ## **Threads: Usuário versus Kernel**  * **Threads do Usuário:**     * seu gerenciamento é feito por uma biblioteca de threads no nível do usuário.   * **Threads do Kernel:**     * suportadas pelo Kernel.  Três principais bibliotecas para threads:  * POSIX Pthreads   * Win32 threads   * Java threads  Exemplos (de SOs com suporte a threads no kernel):  * Windows, Solaris, Linux, Mac OS X  \\--- PÁGINA 24 \\---  ## **Threads: Tipos**  * No modo usuário   * No modo núcleo (kernel)   * Híbrido  \\[Imagem: Threads no modo usuário vs. modo kernel\\]   Dois diagramas. À esquerda, \\\"Threads no modo usuário\\\": a tabela de threads e o sistema de run-time estão no espaço do usuário, dentro de cada processo. O Kernel só vê a tabela de processos. À direita, \\\"Threads no modo kernel\\\": tanto a tabela de processos quanto a de threads estão no espaço do kernel.   \\--- PÁGINA 25 \\---  ## **Threads no Modo usuário**  * Implementada totalmente no espaço do usuário.   * Por meio de uma biblioteca (criação, exclusão, execução, etc.).   * Criação e escalonamento são realizados sem o conhecimento do kernel.   * Para o kernel, é como se rodasse um programa monothread.   * Gerenciadas como processos no kernel.  \\--- PÁGINA 26 \\---  ## **Threads no Modo usuário**  * Cada processo possui sua própria tabela de threads.   * Funciona como uma tabela de processos, gerenciada pelo runtime.   * Controle apenas as propriedades da thread (PC, ponteiro da pilha, registradores, estado, etc.).  \\--- PÁGINA 27 \\---  ## **Threads no Modo usuário \\- Escalonamento**  * O núcleo escolhe um processo e passa o controle a ele, que escolhe uma thread.   * A gerência da thread fica no espaço do usuário e o núcleo só escalona em nível de processo.   * Não pode ser visualizada pelo núcleo.  \\[Imagem: Escalonamento de threads de usuário\\]   Um diagrama mostrando que primeiro (1) o Kernel escolhe um processo (Process A). Depois (2), o sistema de runtime dentro do Processo A escolhe uma thread para rodar. Uma sequência de execução possível é A1, A2, A3, A1... Uma sequência impossível é A1, B1, A2, B2...   \\--- PÁGINA 28 \\---  ## **Threads no Modo usuário \\- Escalonamento: Modelo N:1 (Muitos-para-um)**  * Muitas threads de nível de usuário mapeadas para uma única thread do kernel.  \\[Imagem: Modelo N:1\\]   Um diagrama mostrando vários processos (Processo Pa, Processo Pb). Dentro de cada um, várias user threads são gerenciadas por uma biblioteca. Todas as threads de um processo são mapeadas para uma única thread de núcleo.   \\--- PÁGINA 29 \\---  ## **Threads: Modo kernel**  * Suportada diretamente pelo S.O.   * Criação, escalonamento e gerenciamento são feitos pelo kernel.   * O núcleo possui tabela de threads (com todas as threads do sistema) e tabela de processos separadas.   * Os algoritmos de escalonamento mais utilizados são Round-Robin e Prioridade.  \\--- PÁGINA 30 \\---  ## **Threads: Modo kernel**  * Gerenciar threads em modo núcleo é mais caro devido à alternância entre modo usuário e modo kernel.   * Mudança de contexto pode envolver threads.   * Criar e destruir threads no núcleo é mais caro.   * Exemplo (mapeamento 1:1): Linux, família Windows, OS/2, Solaris 9\\.  \\--- PÁGINA 31 \\---  ## **Threads no Modo kernel \\- Escalonamento: Modelo 1:1 (Um-para-um)**  * Cada thread de nível do usuário mapeada para uma thread do kernel.  \\[Imagem: Modelo 1:1\\]   Um diagrama mostrando várias user threads e cada uma delas sendo mapeada para uma kernel thread separada.   \\--- PÁGINA 32 \\---  ## **Threads: Modo kernel \\- Escalonamento**  * O núcleo escolhe a thread diretamente.   * A thread é quem recebe o quantum, sendo suspensa se excedê-lo.   * Thread bloqueada por E/S não bloqueia o processo.   * Permite múltiplas threads em paralelo.  \\--- PÁGINA 33 \\---  ## **Multithreads: Modelo Muitos-para-muitos (N:M)**  * Permite muitas threads do nível do usuário serem mapeados para muitas threads do kernel.   * Permite que o sistema operacional crie um número suficiente de threads do kernel.   * Exemplos: Solaris (versões \\< 9), Windows com ThreadFiber.  \\[Imagem: Modelo N:M\\]   Um diagrama mostrando várias user threads sendo mapeadas para um conjunto menor de kernel threads.   \\--- PÁGINA 34 \\---  ## **Threads: Modo híbrido**  * Similar ao modelo N:M, exceto pela permissão de uma thread do usuário ser ligada (bound) à thread do kernel.   * Exemplos: IRIX, HP-UX, Tru64 UNIX, Solaris 8 e anteriores.  \\[Imagem: Modelo Híbrido\\]   O diagrama mostra tanto um mapeamento N:M (várias threads de usuário para várias de kernel) quanto um mapeamento 1:1 (uma thread de usuário ligada diretamente a uma de kernel).   \\--- PÁGINA 35 \\---  ## **Multithreads: Modelos**  \\[Imagem: Tabela comparando Threads de Usuário e de Kernel\\]   \\*Uma tabela comparando as duas abordagens:  * **User Level:** Implementada pelo usuário, não reconhecida pelo SO, fácil implementação, troca de contexto rápida, bloqueio de uma thread bloqueia o processo inteiro. Ex: Java threads, POSIX.   * **Kernel Level:** Implementada pelo SO, reconhecida pelo SO, implementação complexa, troca de contexto lenta, bloqueio de uma thread não bloqueia as outras. Ex: Windows, Solaris.\\*  \\--- PÁGINA 36 \\---  ## **Multithreads: Bibliotecas**  * Fornecem ao programador uma API (Application Programming Interface) para a criação e gerência de threads.   * Duas formas principais de implementação:     * Biblioteca totalmente no espaço do usuário.     * Biblioteca no nível do kernel, suportada pelo S.O.  \\--- PÁGINA 37 \\---  ## **Multithreads: PThreads**  * Uma API padrão POSIX (IEEE 1003.1c) para a criação e sincronização de threads.   * Pode ser fornecida tanto no nível do usuário quanto no nível do kernel.   * API especifica o comportamento da biblioteca de thread.   * Comum nos sistemas operacionais Unix-like (Linux, Mac OS X, Solaris).  \\--- PÁGINA 38 \\---  ## **Multithreads: Java Threads**  * Threads Java são gerenciadas pela JVM.   * Implementada no modelo de threads fornecido pelo S.O. subjacente.   * Threads Java podem ser criadas:     * Estendendo a classe Thread.     * Implementando a interface Runnable.  \\--- PÁGINA 39 \\---  ## **Threads: Questões relacionadas**  * Semântica das chamadas de sistema fork() e exec().   * Cancelamento de uma Thread.   * Tratamento de Sinais.   * Thread pools.   * Dados específicos da Thread.   * Ativações do Escalonador \\- Scheduler activations.  \\--- PÁGINA 40 \\---  ## **Threads: Semântica fork() e exec()**  * fork() duplica somente a thread que a chamou ou todas as threads?   * Se uma thread invoca a chamada de sistema exec(), o programa especificado no parâmetro irá substituir todo o processo \\- incluindo todas as threads.   * O tipo de chamada fork() a ser utilizada depende da aplicação.  \\--- PÁGINA 41 \\---  ## **Threads: Cancelamento de uma thread**  * Terminação de um thread antes de sua finalização.   * Duas abordagens no geral:     * **Cancelamento Assíncrono:** termina a thread-alvo imediatamente.     * **Cancelamento Postergado (Deferred cancellation):** permite que a thread alvo periodicamente verifique se ela deve ser cancelada.  \\--- PÁGINA 42 \\---  ## **Threads: Cancelamento de uma thread**  * Cancelamento de uma thread significa encerrá-la antes do término de sua execução, antes de completar sua tarefa.   * Por exemplo, se múltiplas threads estão buscando concorrentemente em uma base de dados e uma delas retorna o resultado esperado, todas as outras devem ser canceladas.  \\--- PÁGINA 43 \\---  ## **Threads: Cancelamento de uma thread**  * Outra ocorrência é quando o usuário pressiona o botão para parar o carregamento de uma página web no browser. A thread que é cancelada é frequentemente chamada de thread-alvo.   * A dificuldade de cancelamento ocorre em situações onde os recursos foram alocados a uma thread cancelada ou quando a thread é cancelada enquanto atualiza dados compartilhados com outra threads.  \\--- PÁGINA 44 \\---  ## **Threads: Cancelamento de uma thread**  * O cancelamento-padrão é o autorizado (deferred). Neste caso, o cancelamento ocorre quando a thread alcança ou chega ao **ponto de cancelamento**.   * Uma estratégia para estabelecer um ponto de cancelamento é invocar a função pthread\\_testcancel().  \\--- PÁGINA 45 \\---  ## **Threads: Tratamento de sinais**  * Sinais são usados em sistemas UNIX para notificar um processo que um evento em particular ocorreu.   * Um tratamento de sinal é usado para processar sinais:     1. Um sinal é gerado por um evento em particular.     2. Um sinal é entregue a um processo.     3. O sinal é tratado.  \\--- PÁGINA 46 \\---  ## **Threads: Tratamento de sinais**  * Todo sinal possui um tratamento-padrão que o kernel executa quando o mesmo é recebido. O tratamento padronizado pode ser sobrescrito pelo usuário.   * Tratamentos de sinais em programas de uma única thread (single-threaded) são diretos: os sinais são sempre entregues ao processo.  \\--- PÁGINA 47 \\---  ## **Threads: Tratamento de sinais**  O tratamento de sinais em programas multithread podem seguir as seguintes alternativas:  * Entrega do sinal à thread ao qual o sinal se aplica.   * Entrega do sinal a todas as threads do processo.   * Entrega do sinal a certas/algumas threads do processo.   * Definição de uma thread específica para o recebimento de todos os sinais do processo.  \\--- PÁGINA 48 \\---  ## **Thread Pools**  * A primeira questão acerca do tempo de criação de uma thread está relacionada ao fato de que a mesma será descartada após a finalização de sua tarefa.   * A criação de inúmeras threads pode utilizar todos os recursos disponibilizados pelo sistema, como tempo de CPU ou memória. Uma solução para esta questão é a criação de um pool de threads.  \\--- PÁGINA 49 \\---  ## **Thread Pools**  * A ideia geral é a criação de um certo número de threads no processo de inicialização e alocá-las neste pool, onde elas irão aguardar para serem utilizadas.   * Quando o servidor receber uma requisição, caso existe uma thread disponível ela será acordada e executará a requisição. Assim que encerrar a tarefa, retorna ao pool.  \\--- PÁGINA 50 \\---  ## **Thread Pools**  * Pools de Threads oferecem os seguintes benefícios:     * Responder a uma requisição com uma thread existente é mais rápido do que aguardar pela criação de uma thread.     * O pool de threads limita o número de requisições a serem atendidas simultaneamente.     * Separar a tarefa a ser executada do mecanismo de criação de tarefas permite o uso de diferentes estratégias.  \\--- PÁGINA 51 \\---  ## **Thread Pools**  * O número de threads pode ser determinado de modo heurístico baseado no número de CPUs do sistema, quantidade de memória física, número de clientes e requisições esperado, etc.   * Pools mais sofisticados podem sofrer ajuste dinâmico do número de threads de acordo com algumas regras e padrões.  \\--- PÁGINA 52 \\---  ## **Thread Pools (Resumo)**  * Cria um número de threads em um pool onde aguardam por trabalho.   * Vantagens:     * Normalmente mais rápido servir uma requisição com um thread existente do que criar uma nova thread.     * Permite o número de threads da aplicação(ões) serem limitadas (bound) ao tamanho do pool.  \\--- PÁGINA 53 \\---  ## **Thread: Paralelismo**  * **Grand Central Dispatch (GCD)** \\- é uma tecnologia para sistemas operacionais da Apple \\- Mac OS X e iOS. Ela permite que desenvolvedores de aplicações identifiquem seções do código que podem ser executadas em paralelo.   * **OpenMP** é um conjunto de diretivas de compiladores que fornecem suporte à programação paralela em ambientes de memória compartilhada.  \\--- PÁGINA 54 \\---  ## **Thread: Armazenamento de dados específicos**  * Em algumas situações as threads podem necessitar de suas próprias cópias dos dados. Esta fato é chamado de **Thread-local storage (TLS)**.   * É fácil confundir TLS com variáveis locais:     * Enquanto variáveis locais são visíveis apenas durante a invocação simples da função, TLS são visíveis além da invocação da função.   * Em algumas situações, TLS são similares a dados estáticos (static data).     * A diferença é que TLS é único para cada thread.  \\--- PÁGINA 55 \\---  ## **Thread: Ativação de escalonadores**  * Ambos modelos N:M e Dois-Níveis, requerem comunicação para manter o número apropriado de threads do kernel alocado para a aplicação.   * Ativação de escalonadores fornece **upcalls** \\- um mecanismo de comunicação do kernel para a biblioteca de threads.   * Esta comunicação permite que uma aplicação mantenha o número correto de threads do kernel.  \\--- PÁGINA 56 \\---  ## **Thread: Ativação de escalonadores**  \\[Imagem: Ativação de escalonador para threads de usuário\\]   Um diagrama mostrando o gerenciador de threads (thread manager) no espaço do usuário, que realiza escalonamento cooperativo e preemptivo das threads de usuário. O kernel notifica o gerenciador através de um timer.   \\--- PÁGINA 57 \\---  ## **Thread: Ativação de escalonadores**  * Esta estrutura de dados é tipicamente conhecida como **lightweight process (LWP)**. Para a biblioteca de threads, LWP funciona como um processador virtual onde a aplicação pode escalonar a execução de uma thread.  \\[Imagem: LWP\\]   Um diagrama mostrando a relação: uma user thread roda sobre um lightweight process (LWP), que por sua vez é mapeado para uma kernel thread.   \\--- PÁGINA 58 \\---  ## **Thread: Exemplos de Sistemas Operacionais**  * Threads no Windows XP   * Threads no Linux  \\--- PÁGINA 59 \\---  ## **Threads: Windows XP**  * Implementa o mapeamento um-para-um (1:1), nível do kernel.   * Cada thread contém:     * Um identificador da thread     * Um conjunto de registradores     * Pilhas separadas para o usuário e o kernel     * Área privada de armazenamento de dados   * O conjunto de registradores, pilhas e área privada de armazenamento são conhecidos como o **contexto** das threads.   * As principais estruturas de dados de uma thread são:     * ETHREAD (executive thread block)     * KTHREAD (kernel thread block)     * TEB (thread environment block)  \\--- PÁGINA 60 \\---  ## **Threads: Windows XP**  \\[Imagem: Estruturas de dados de uma thread no Windows\\]   Um diagrama mostrando a relação entre as estruturas de dados de uma thread no Windows. A ETHREAD e a KTHREAD estão no kernel space, enquanto a TEB está no user space.   \\--- PÁGINA 61 \\---  ## **Threads: Linux**  * Linux refere-se à elas como **tarefas (tasks)** em vez de threads.   * A criação de threads é feita via chamada de sistema clone().   * clone() permite que uma tarefa filha compartilhe o espaço de endereçamento da tarefa pai (processo).  \\--- PÁGINA 62 \\---  ## **Threads: Linux**  \\[Imagem: Tabela com flags da chamada clone()\\]   \\*Uma tabela mostrando as flags da chamada clone() no Linux e o que elas significam:  * CLONE\\_FS: Informação do sistema de arquivos é compartilhada.   * CLONE\\_VM: O mesmo espaço de memória é compartilhado.   * CLONE\\_SIGHAND: Manipuladores de sinal são compartilhados.   * CLONE\\_FILES: O conjunto de arquivos abertos é compartilhado.\\*  \\--- PÁGINA 63 \\---  ## **Bibliografia**  * TANENBAUM, Andrew S; BOS, Herbert. **Sistemas operacionais modernos.** 4a ed. São Paulo: Pearson Education do Brasil, 2016\\. Capítulo 2\\.   * DEITEL, H.M; DEITEL, P.J; CHOFFNES,D.R. **Sistemas Operacionais.** 3a ed. São Paulo: Pearson Prentice Hall, 2005\\. Capítulo 4\\.  \\--- PÁGINA 64 \\---   Slide final com o logo da universidade e contato do professor.